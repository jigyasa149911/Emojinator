{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the dependencies.\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils, print_summary\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13199, 2501)\n",
      "       1  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.1509  0.1510  \\\n",
      "13194  9  0    0    0    0    0    0    0    0    0  ...       0       0   \n",
      "13195  9  0    0    0    0    0    0    0    0    1  ...       0       0   \n",
      "13196  9  0    0    0    0    0    0    0    0    0  ...       0       0   \n",
      "13197  9  0    0    0    0    0    0    0    0    0  ...       0       0   \n",
      "13198  9  0    0    0    0    0    0    0    0    0  ...       0       0   \n",
      "\n",
      "       0.1511  0.1512  0.1513  0.1514  0.1515  0.1516  0.1517  0.1518  \n",
      "13194       0       0       0       0       0       0       0       0  \n",
      "13195       0       0       0       0       0       0       0       0  \n",
      "13196       0       0       0       0       0       0       0       0  \n",
      "13197       0       0       0       0       0       0       0       0  \n",
      "13198       0       0       0       0       0       0       0       0  \n",
      "\n",
      "[5 rows x 2501 columns]\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('training_data.csv')\n",
    "print(df.shape)\n",
    "print(df.tail())\n",
    "\n",
    "dataset = np.array(df)\n",
    "np.random.shuffle(dataset)\n",
    "x = dataset\n",
    "y = dataset\n",
    "x = x[:, 1:2501]\n",
    "y = y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[0:12000,:]\n",
    "y_train = x_train/255. #Normalization.\n",
    "x_test = x[12000:13201 , :]\n",
    "y_test = x_test/255. #Normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [2]\n",
      " [8]\n",
      " ...\n",
      " [2]\n",
      " [5]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "y = y.reshape(y.shape[0],1)\n",
    "y_train = y[0:12000, :]\n",
    "print(y_train)\n",
    "y_train = y_train.T\n",
    "y_test = y[12000:13201, :]\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 12000\n",
      "Number of test examples = 1\n",
      "x_train shape = (12000, 2500)\n",
      "y_train shape = (1, 12000)\n",
      "x_test shape = (1199, 2500)\n",
      "y_test shape = (1, 1199)\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples =',x_train.shape[0])\n",
    "print('Number of test examples =',y_train.shape[0])\n",
    "print('x_train shape =',x_train.shape)\n",
    "print('y_train shape =',y_train.shape)\n",
    "print('x_test shape =',x_test.shape)\n",
    "print('y_test shape =',y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape = (12000, 50, 50, 1)\n",
      "x_test shape = (1199, 50, 50, 1)\n",
      "train_y shape = (12000, 12)\n"
     ]
    }
   ],
   "source": [
    "image_x =50\n",
    "image_y =50\n",
    "\n",
    "train_y = np_utils.to_categorical(y_train)\n",
    "test_y =np_utils.to_categorical(y_test)\n",
    "train_y = train_y.reshape(train_y.shape[1],train_y.shape[2])\n",
    "test_y = test_y.reshape(test_y.shape[1],test_y.shape[2])\n",
    "x_train = x_train.reshape(x_train.shape[0], 50, 50, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 50, 50, 1)\n",
    "\n",
    "print('x_train shape =',x_train.shape)\n",
    "print('x_test shape =',x_test.shape)\n",
    "print('train_y shape =',train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(image_x,image_y):\n",
    "    num_of_classes = 12\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5,5), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2) ,strides=(2,2), padding='same'))\n",
    "    model.add(Conv2D(64, (5,5), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2) ,strides=(2,2), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath = 'face_rec_256.h5'\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint1]\n",
    "\n",
    "\n",
    "    return model, callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 12000 samples, validate on 1199 samples\n",
      "Epoch 1/1\n",
      "12000/12000 [==============================] - 123s 10ms/step - loss: 0.4079 - accuracy: 0.9448 - val_loss: 5.0856e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jigyasa\\Documents\\satyam anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Error :0.00%\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 19, 19, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              6554624   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                12300     \n",
      "=================================================================\n",
      "Total params: 6,619,020\n",
      "Trainable params: 6,619,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, callbacks_list = keras_model(image_x,image_y)\n",
    "model.fit(x_train, train_y, validation_data =(x_test, test_y),\n",
    "          epochs=1, batch_size=64, callbacks=callbacks_list)\n",
    "scores = model.evaluate(x_test, test_y, verbose=0)\n",
    "print('CNN Error :%.2f%%'%(100-scores[1]*100))\n",
    "print_summary(model)\n",
    "\n",
    "model.save('HandEmo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
